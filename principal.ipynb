{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435744d3-ff27-42f3-9b30-01111f205af9",
   "metadata": {},
   "source": [
    "# 1. CONFIGURAÇÃO INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1c24d-044d-4572-88c5-ad5e2a17757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA DE CONFIGURAÇÃO: IMPORTS E PARÂMETROS GLOBAIS\n",
    "# =============================================================================\n",
    "\n",
    "# --- Imports de Bibliotecas Padrão ---\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "#!pip install umap-learn\n",
    "# --- Imports de Análise de Dados e Numérica ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# --- Imports de Machine Learning (Scikit-learn) ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans, HDBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, \n",
    "    davies_bouldin_score, \n",
    "    calinski_harabasz_score\n",
    ")\n",
    "from sklearn.preprocessing import MinMaxScaler # Para visualização\n",
    "\n",
    "# --- Imports de Bibliotecas Astronômicas ---\n",
    "from astropy.timeseries import LombScargle\n",
    "from astropy import units as u\n",
    "\n",
    "# --- Imports de Redução de Dimensionalidade e Visualização ---\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# --- Configurações Globais ---\n",
    "# Suprimir warnings para um notebook limpo\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração de Logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Semente aleatória para reprodutibilidade\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "logger.info(f\"Semente aleatória global definida como {RANDOM_STATE}\")\n",
    "\n",
    "# Configurações de Visualização (Matplotlib e Seaborn)\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.format'] = 'pdf' # Formato vetorial para publicações\n",
    "\n",
    "# Diretório para salvar figuras\n",
    "FIG_DIR = \"figures\"\n",
    "if not os.path.exists(FIG_DIR):\n",
    "    os.makedirs(FIG_DIR)\n",
    "    logger.info(f\"Diretório de figuras criado em: {FIG_DIR}\")\n",
    "\n",
    "# --- Funções Auxiliares ---\n",
    "def save_figure(fig, name, tight_layout=True):\n",
    "    \"\"\"\n",
    "    Salva uma figura matplotlib em múltiplos formatos (PDF, PNG) \n",
    "    no diretório de figuras definido.\n",
    "    \"\"\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    path_pdf = os.path.join(FIG_DIR, f\"{name}.pdf\")\n",
    "    path_png = os.path.join(FIG_DIR, f\"{name}.png\")\n",
    "    \n",
    "    fig.savefig(path_pdf, bbox_inches='tight')\n",
    "    fig.savefig(path_png, bbox_inches='tight')\n",
    "    logger.info(f\"Figura salva em {path_pdf} e {path_png}\")\n",
    "\n",
    "\n",
    "def sm():\n",
    "    plt.minorticks_on()\n",
    "    plt.tick_params(axis='both',which='minor', direction = \"in\",top = True,right = True, length=5,width=1,labelsize=15)\n",
    "    plt.tick_params(axis='both',which='major', direction = \"in\",top = True,right = True, length=8,width=1,labelsize=15)\n",
    "    plt.tick_params(axis='both',which='minor', direction = \"in\",bottom = True,right = True, length=5,width=1,labelsize=15)\n",
    "    plt.tick_params(axis='both',which='major', direction = \"in\",bottom = True,right = True, length=8,width=1,labelsize=15)\n",
    "\n",
    "\n",
    "\n",
    "logger.info(\"Ambiente configurado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4979893-9a6a-494f-927b-927d6579e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# REGISTRO LOCAL DA FONTE COURIER PRIME (EMBUTIDA NO PROJETO)\n",
    "# =============================================================================\n",
    "import matplotlib.font_manager as fm\n",
    "from pathlib import Path\n",
    "\n",
    "FONT_DIR = Path(\"fonts\")\n",
    "\n",
    "for font_path in FONT_DIR.glob(\"*.ttf\"):\n",
    "    fm.fontManager.addfont(str(font_path))\n",
    "\n",
    "# Verificação explícita\n",
    "available_fonts = {f.name for f in fm.fontManager.ttflist}\n",
    "assert \"Courier Prime\" in available_fonts, \"Courier Prime NÃO encontrada!\"\n",
    "\n",
    "print(\"Courier Prime registrada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e0286-ee30-4067-8e87-8869d5699a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5166e-fa30-42a1-9f4a-697de55ec89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "[f.name for f in fm.fontManager.ttflist if \"Courier Prime\" in f.name]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURAÇÃO GLOBAL DE FONTE – PAPER (Courier Prime)\n",
    "# =============================================================================\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams.update({\n",
    "\n",
    "    # Fonte principal\n",
    "    \"font.family\": \"monospace\",\n",
    "    \"font.monospace\": [\"Courier Prime\"],\n",
    "\n",
    "    # Tamanhos base (ajuste fino depois, se necessário)\n",
    "    \"font.size\": 13,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 15,\n",
    "    \"legend.fontsize\": 12,\n",
    "\n",
    "    # Mathtext (importante para labels com símbolos)\n",
    "    \"mathtext.fontset\": \"custom\",\n",
    "    \"mathtext.rm\": \"Courier Prime\",\n",
    "    \"mathtext.it\": \"Courier Prime:italic\",\n",
    "    \"mathtext.bf\": \"Courier Prime:bold\",\n",
    "\n",
    "    # Aparência de eixos (paper-grade)\n",
    "    \"axes.linewidth\": 1.0,\n",
    "\n",
    "    # Exportação\n",
    "    \"pdf.fonttype\": 42,   # TrueType → garante embedding da fonte\n",
    "    \"ps.fonttype\": 42,\n",
    "\n",
    "    \"savefig.format\": \"pdf\",\n",
    "    \"savefig.dpi\": 300,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d9020-0e70-46b0-b76e-ab933e23131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e4b08-f86b-4b8e-8653-883654184fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA DE VERIFICAÇÃO DE VERSÃO\n",
    "# =============================================================================\n",
    "import sys\n",
    "import sklearn\n",
    "import astropy\n",
    "import statsmodels\n",
    "import plotly\n",
    "\n",
    "logger.info(f\"Versão Python: {sys.version.split()}\")\n",
    "logger.info(f\"Versão NumPy: {np.__version__}\")\n",
    "logger.info(f\"Versão Pandas: {pd.__version__}\")\n",
    "logger.info(f\"Versão Scikit-learn: {sklearn.__version__}\")\n",
    "logger.info(f\"Versão Astropy: {astropy.__version__}\")\n",
    "logger.info(f\"Versão UMAP: {umap.__version__}\")\n",
    "logger.info(f\"Versão Plotly: {plotly.__version__}\")\n",
    "logger.info(f\"Versão Seaborn: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a79ff-b2f8-4443-8084-5dce25a30ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "def sm_ted(ax=None, labelsize=15, minor_len=5, major_len=8, width=1):\n",
    "    \"\"\"\n",
    "    Aplica estilo tipo SuperMongo em um eixo (ax).\n",
    "    Se ax=None, aplica no eixo atual (plt.gca()).\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Minor ticks (em ambos os eixos)\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "    # Ticks: major/minor, em todas as bordas\n",
    "    ax.tick_params(axis='both', which='minor',\n",
    "                   direction='in', top=True, right=True,\n",
    "                   length=minor_len, width=width, labelsize=labelsize)\n",
    "    ax.tick_params(axis='both', which='major',\n",
    "                   direction='in', top=True, right=True,\n",
    "                   length=major_len, width=width, labelsize=labelsize)\n",
    "\n",
    "    # Também garante bottom/left (por segurança)\n",
    "    ax.tick_params(axis='both', which='minor',\n",
    "                   direction='in', bottom=True, left=True)\n",
    "    ax.tick_params(axis='both', which='major',\n",
    "                   direction='in', bottom=True, left=True)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59451d03-6367-49dc-838c-0fc61b6c2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA DE CARGA DE DADOS\n",
    "# =============================================================================\n",
    "logger.info(\"Iniciando Etapa 2.1: Aquisição de Dados...\")\n",
    "\n",
    "# --- Caminhos dos arquivos de dados ---\n",
    "DATA_PATH_TS = \"table3.csv\"\n",
    "DATA_PATH_PARAMS = \"table2.csv\"\n",
    "DATA_PATH_CYCLES = \"table4.csv\"\n",
    "\n",
    "# --- Carregar Séries Temporais (Entrada Principal) ---\n",
    "try:\n",
    "    df_timeseries = pd.read_csv(DATA_PATH_TS)\n",
    "    logger.info(f\"Carregado {DATA_PATH_TS}: {df_timeseries.shape} observações\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"ERRO: Arquivo {DATA_PATH_TS} não encontrado.\")\n",
    "    # Adicionar aqui lógica de download de backup se necessário\n",
    "    df_timeseries = pd.DataFrame() # Placeholder\n",
    "\n",
    "# --- Carregar Parâmetros Estelares (Validação) ---\n",
    "try:\n",
    "    df_params = pd.read_csv(DATA_PATH_PARAMS)\n",
    "    logger.info(f\"Carregado {DATA_PATH_PARAMS}: {df_params.shape} estrelas (para validação)\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"ERRO: Arquivo {DATA_PATH_PARAMS} não encontrado.\")\n",
    "    df_params = pd.DataFrame()\n",
    "\n",
    "# --- Carregar Ciclos Conhecidos (Validação) ---\n",
    "try:\n",
    "    df_cycles = pd.read_csv(DATA_PATH_CYCLES)\n",
    "    logger.info(f\"Carregado {DATA_PATH_CYCLES}: {df_cycles.shape} ciclos (para validação)\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"ERRO: Arquivo {DATA_PATH_CYCLES} não encontrado.\")\n",
    "    df_cycles = pd.DataFrame()\n",
    "\n",
    "logger.info(\"Dados carregados. Iniciando pré-processamento de séries temporais...\")\n",
    "\n",
    "\n",
    "# --- Limpeza e Pré-processamento de Séries Temporais (df_timeseries) ---\n",
    "if not df_timeseries.empty:\n",
    "    # Renomear colunas para clareza e consistência\n",
    "    df_timeseries = df_timeseries.rename(columns={\n",
    "        'Name': 'star_id',\n",
    "        'BJD': 'time_bjd',\n",
    "        'S': 's_index'\n",
    "    })\n",
    "\n",
    "    # CORREÇÃO: Limpar espaços em branco dos nomes das estrelas\n",
    "    df_timeseries['star_id'] = df_timeseries['star_id'].str.strip()\n",
    "\n",
    "    # Selecionar apenas as colunas necessárias\n",
    "    cols_to_keep = ['star_id', 'time_bjd', 's_index']\n",
    "    df_timeseries = df_timeseries[cols_to_keep]\n",
    "\n",
    "    # Converter BJD (dias) para Anos Decimais. \n",
    "    # BJD em table3.csv é BJD-2440000 [4]\n",
    "    df_timeseries['time_yr'] = df_timeseries['time_bjd'] / 365.25\n",
    "\n",
    "    # Verificar NaNs nos dados de entrada\n",
    "    nan_count = df_timeseries.isna().sum().sum()\n",
    "    logger.info(f\"Total de valores NaN encontrados nas séries temporais brutas: {nan_count}\")\n",
    "\n",
    "    # Remover quaisquer linhas com NaNs no S-index ou no tempo\n",
    "    df_timeseries = df_timeseries.dropna()\n",
    "\n",
    "    # Verificar o número de estrelas únicas\n",
    "    n_unique_stars = df_timeseries['star_id'].nunique()\n",
    "    logger.info(f\"Dados de séries temporais limpos para {n_unique_stars} estrelas únicas.\")\n",
    "\n",
    "    # Exibir o cabeçalho dos dados processados\n",
    "    print(\"\\n--- Cabeçalho das Séries Temporais Processadas (df_timeseries) ---\")\n",
    "    print(df_timeseries.head())\n",
    "else:\n",
    "    logger.error(\"DataFrames de séries temporais estão vazios. Encerrando.\")\n",
    "\n",
    "# --- Limpeza dos dados de validação ---\n",
    "if not df_params.empty:\n",
    "    df_params = df_params.rename(columns={'Name': 'star_id'})\n",
    "    # CORREÇÃO: Limpar espaços em branco dos nomes das estrelas [4]\n",
    "    df_params['star_id'] = df_params['star_id'].str.strip()\n",
    "\n",
    "if not df_cycles.empty:\n",
    "    df_cycles = df_cycles.rename(columns={'Name': 'star_id', 'Per': 'val_period'})\n",
    "    # CORREÇÃO: Limpar espaços em branco dos nomes das estrelas [4]\n",
    "    df_cycles['star_id'] = df_cycles['star_id'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670cdc4-30d8-40d8-b296-66e20a46d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_ts.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61b57f-c8e3-4cb7-a813-ba530d1cf7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA DE VISUALIZAÇÃO EXPLORATÓRIA\n",
    "# =============================================================================\n",
    "logger.info(\"Plotando séries temporais de exemplo...\")\n",
    "\n",
    "if not df_timeseries.empty:\n",
    "    # Agrupar dados para acesso rápido\n",
    "    grouped_ts = df_timeseries.groupby('star_id')\n",
    "\n",
    "    # Identificar estrelas de exemplo (baseado no SSD de table2.csv)\n",
    "    # HD 18632 (alta atividade, SSD=0.02275) \n",
    "    # HD 86728 (baixa atividade, SSD=0.00102) \n",
    "    star_active = \"HD 18632\"\n",
    "    star_inactive = \"HD 86728\"\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=False)\n",
    "    sm()\n",
    "\n",
    "    # Plot 1: Estrela Ativa\n",
    "    if star_active in grouped_ts.groups:\n",
    "        data_active = grouped_ts.get_group(star_active)\n",
    "        ax1.plot(data_active['time_yr'], data_active['s_index'], \n",
    "                 marker='o', markersize=4, linestyle='none', alpha=0.7)\n",
    "        ax1.set_title(f'Exemplo de Estrela Ativa: {star_active}')\n",
    "        ax1.set_ylabel('S-index')\n",
    "        sm()\n",
    "    else:\n",
    "        logger.warning(f\"Estrela de exemplo {star_active} não encontrada.\")\n",
    "\n",
    "    # Plot 2: Estrela Inativa\n",
    "    if star_inactive in grouped_ts.groups:\n",
    "        data_inactive = grouped_ts.get_group(star_inactive)\n",
    "        ax2.plot(data_inactive['time_yr'], data_inactive['s_index'], \n",
    "                 marker='o', markersize=4, linestyle='none', alpha=0.7, color='C1')\n",
    "        ax2.set_title(f'Exemplo de Estrela Inativa: {star_inactive}')\n",
    "        ax2.set_ylabel('S-index')\n",
    "        ax2.set_xlabel('Ano (BJD)')\n",
    "    else:\n",
    "        logger.warning(f\"Estrela de exemplo {star_inactive} não encontrada.\")\n",
    "\n",
    "        \n",
    "    sm()\n",
    "    save_figure(fig, \"01_exploratory_timeseries_examples\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f931a80-fff2-4bdb-a7ad-3730e24ffa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# =============================================================================\n",
    "# CÉLULA DE VISUALIZAÇÃO EXPLORATÓRIA (sm_ted, eixo x contínuo, sem espaço)\n",
    "# =============================================================================\n",
    "logger.info(\"Plotando séries temporais de exemplo (sm_ted, eixo x contínuo)...\")\n",
    "\n",
    "if not df_timeseries.empty:\n",
    "    grouped_ts = df_timeseries.groupby('star_id')\n",
    "\n",
    "    star_active = \"HD 18632\"\n",
    "    star_inactive = \"HD 86728\"\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        2, 1,\n",
    "        figsize=(12, 8),\n",
    "        sharex=True,\n",
    "        gridspec_kw={'hspace': 0.0}   # sem espaço entre painéis\n",
    "    )\n",
    "\n",
    "    # --- formatador do eixo y com 3 casas decimais ---\n",
    "    yfmt = FormatStrFormatter('%.3f')\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Estrela Ativa\n",
    "    # -------------------------------------------------------------------------\n",
    "    if star_active in grouped_ts.groups:\n",
    "        data_active = grouped_ts.get_group(star_active)\n",
    "\n",
    "        ax1.plot(\n",
    "            data_active['time_yr'],\n",
    "            data_active['s_index'],\n",
    "            marker='o',\n",
    "            markersize=4,\n",
    "            linestyle='none',\n",
    "            alpha=0.7\n",
    "        )\n",
    "\n",
    "        ax1.set_ylabel('S-index', fontsize=14)\n",
    "        ax1.yaxis.set_major_formatter(yfmt)\n",
    "\n",
    "        # Nome abaixo do painel (NÃO clipa)\n",
    "        ax1.annotate(\n",
    "            f\"{star_active} (active)\",\n",
    "            xy=(0.5, -0.13), xycoords='axes fraction',\n",
    "            ha='center', va='top', fontsize=13,\n",
    "            annotation_clip=False\n",
    "        )\n",
    "\n",
    "        sm_ted(ax1)\n",
    "        ax1.tick_params(labelbottom=False)  # sem labels no painel superior\n",
    "    else:\n",
    "        logger.warning(f\"Estrela de exemplo {star_active} não encontrada.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Estrela Inativa\n",
    "    # -------------------------------------------------------------------------\n",
    "    if star_inactive in grouped_ts.groups:\n",
    "        data_inactive = grouped_ts.get_group(star_inactive)\n",
    "\n",
    "        ax2.plot(\n",
    "            data_inactive['time_yr'],\n",
    "            data_inactive['s_index'],\n",
    "            marker='o',\n",
    "            markersize=4,\n",
    "            linestyle='none',\n",
    "            alpha=0.7,\n",
    "            color='C1'\n",
    "        )\n",
    "\n",
    "        ax2.set_ylabel('S-index', fontsize=14)\n",
    "        ax2.set_xlabel('Year (BJD)', fontsize=14)\n",
    "        ax2.yaxis.set_major_formatter(yfmt)\n",
    "\n",
    "        # Nome abaixo do painel (um pouco mais baixo por causa do xlabel)\n",
    "        ax1.text(\n",
    "            0.98, 0.95,\n",
    "            f\"{star_active}\",\n",
    "            transform=ax1.transAxes,\n",
    "            ha='right',\n",
    "            va='top',\n",
    "            fontsize=13\n",
    "        )\n",
    "\n",
    "        ax2.text(\n",
    "            0.98, 0.95,\n",
    "            f\"{star_inactive}\",\n",
    "            transform=ax2.transAxes,\n",
    "            ha='right',\n",
    "            va='top',\n",
    "            fontsize=13\n",
    "        )\n",
    "\n",
    "        sm_ted(ax2)\n",
    "    else:\n",
    "        logger.warning(f\"Estrela de exemplo {star_inactive} não encontrada.\")\n",
    "\n",
    "    # Margens externas para garantir que os textos abaixo apareçam\n",
    "    fig.subplots_adjust(left=0.1, right=0.97, top=0.97, bottom=0.16)\n",
    "\n",
    "    # MUITO importante: não usar tight_layout aqui, senão pode cortar anotações\n",
    "    save_figure(fig, \"01_exploratory_timeseries_examples\", tight_layout=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29aa3-28dc-4264-b4fb-3a05a0c6487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 2.2: ENGENHARIA DE FEATURES ESTATÍSTICAS\n",
    "# =============================================================================\n",
    "logger.info(\"Iniciando Etapa 2.2: Engenharia de Features Estatísticas...\")\n",
    "start_time = time.time()\n",
    "\n",
    "def calculate_statistical_features(group):\n",
    "    \"\"\"\n",
    "    Calcula um vetor de features estatísticas para uma única estrela (grupo).\n",
    "    \n",
    "    Impõe um corte de n_obs >= 10 para robustez estatística.\n",
    "    \n",
    "    Args:\n",
    "        group (pd.DataFrame): DataFrame contendo dados para uma única estrela.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: Série contendo as features calculadas ou NaNs se n_obs < 10.\n",
    "    \"\"\"\n",
    "    s = group['s_index']\n",
    "    n_obs = s.count()\n",
    "    \n",
    "    # Corte de robustez: Requerer pelo menos 10 observações\n",
    "    if n_obs < 10:\n",
    "        feature_names = ['n_obs', 'mean', 'std', 'skew', 'kurtosis', \n",
    "                         'amplitude_p95_p5', 'median']\n",
    "        return pd.Series([n_obs] + [np.nan] * 6, index=feature_names)\n",
    "\n",
    "    # Calcular features\n",
    "    try:\n",
    "        features = {\n",
    "            'n_obs': n_obs,\n",
    "            'mean': s.mean(),\n",
    "            'std': s.std(),\n",
    "            'skew': s.skew(),\n",
    "            'kurtosis': s.kurtosis(),\n",
    "            'amplitude_p95_p5': s.quantile(0.95) - s.quantile(0.05),\n",
    "            'median': s.median()\n",
    "        }\n",
    "        return pd.Series(features)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Falha ao calcular estatísticas para um grupo: {e}\")\n",
    "        feature_names = ['n_obs', 'mean', 'std', 'skew', 'kurtosis', \n",
    "                         'amplitude_p95_p5', 'median']\n",
    "        return pd.Series([n_obs] + [np.nan] * 6, index=feature_names)\n",
    "\n",
    "# Agrupar por estrela\n",
    "if 'grouped_ts' not in locals():\n",
    "    grouped_ts = df_timeseries.groupby('star_id')\n",
    "\n",
    "# Aplicar a função a todos os grupos (estrelas)\n",
    "stat_features = grouped_ts.apply(calculate_statistical_features)\n",
    "\n",
    "# --- Análise Pós-Cálculo ---\n",
    "initial_star_count = len(stat_features)\n",
    "logger.info(f\"Features estatísticas calculadas para {initial_star_count} estrelas.\")\n",
    "\n",
    "# Remover estrelas que não passaram no corte (n_obs < 10)\n",
    "# Elas terão NaNs em todas as colunas de features\n",
    "stat_features_clean = stat_features.dropna(subset=['mean'])\n",
    "final_star_count = len(stat_features_clean)\n",
    "stars_dropped = initial_star_count - final_star_count\n",
    "\n",
    "logger.info(f\"{stars_dropped} estrelas removidas devido a n_obs < 10.\")\n",
    "logger.info(f\"{final_star_count} estrelas retidas para a próxima etapa.\")\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f\"Engenharia de features estatísticas concluída em {end_time - start_time:.2f} segundos.\")\n",
    "\n",
    "print(\"\\n--- Cabeçalho da Matriz de Features Estatísticas (stat_features_clean) ---\")\n",
    "print(stat_features_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c91b3-fee7-4a15-9bc8-98ad8313c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA DE VISUALIZAÇÃO: DISTRIBUIÇÃO DAS FEATURES ESTATÍSTICAS\n",
    "# =============================================================================\n",
    "logger.info(\"Gerando pairplot das features estatísticas...\")\n",
    "\n",
    "# Usamos apenas as features, não o n_obs\n",
    "features_for_plot = stat_features_clean.drop(columns=['n_obs'])\n",
    "\n",
    "# O Pairplot pode ser lento, usamos uma amostra se o dataset for muito grande\n",
    "if len(features_for_plot) > 1000:\n",
    "    logger.warning(\"Dataset grande, usando amostra de 1000 pontos para o pairplot.\")\n",
    "    plot_data = features_for_plot.sample(1000, random_state=RANDOM_STATE)\n",
    "else:\n",
    "    plot_data = features_for_plot\n",
    "\n",
    "# Gerar o \"corner plot\" (pairplot)\n",
    "g = sns.pairplot(\n",
    "    plot_data, \n",
    "    diag_kind='kde', \n",
    "    corner=True,\n",
    "    plot_kws={'alpha': 0.4, 's': 10}, # s=marker size\n",
    "    diag_kws={'fill': True}\n",
    ")\n",
    "#g.fig.suptitle(\"Distribuição e Correlação das Features Estatísticas\", y=1.02, fontsize=16)\n",
    "\n",
    "# Salvar figura\n",
    "# O 'g' do seaborn é um PairGrid, acessamos a figura via g.fig\n",
    "save_figure(g.fig, \"02_statistical_features_pairplot\")\n",
    "plt.show()\n",
    "\n",
    "# --- Matriz de Correlação ---\n",
    "logger.info(\"Calculando matriz de correlação...\")\n",
    "corr_matrix = features_for_plot.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    corr_matrix, \n",
    "    annot=True, \n",
    "    fmt='.2f', \n",
    "    cmap='vlag', \n",
    "    center=0, \n",
    "    ax=ax\n",
    ")\n",
    "#ax.set_title(\"Matriz de Correlação das Features Estatísticas\")\n",
    "sm()\n",
    "save_figure(fig, \"03_statistical_features_correlation_matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367eee6-6505-476a-b4d5-9f771903c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 2.3: ENGENHARIA DE FEATURES DE PERIODICIDADE (LOMB-SCARGLE)\n",
    "# =============================================================================\n",
    "logger.info(\"Iniciando Etapa 2.3: Engenharia de Features de Periodicidade...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- Constantes do Periodograma ---\n",
    "MIN_PERIOD_YR = 2.0   # Período mínimo de busca (anos)\n",
    "MAX_PERIOD_YR = 25.0  # Período máximo de busca (anos)\n",
    "N_FREQ_POINTS = 1000  # Resolução da grade de frequência\n",
    "N_BOOTSTRAPS_FAP = 100 # Número de bootstraps para FAP (compromisso velocidade/precisão)\n",
    "\n",
    "# Converter períodos para grade de frequência\n",
    "MIN_FREQ = 1.0 / MAX_PERIOD_YR\n",
    "MAX_FREQ = 1.0 / MIN_PERIOD_YR\n",
    "frequency_grid = np.linspace(MIN_FREQ, MAX_FREQ, N_FREQ_POINTS)\n",
    "logger.info(f\"Grade de frequência LS definida de {MIN_FREQ:.3f} a {MAX_FREQ:.3f} 1/ano.\")\n",
    "\n",
    "def calculate_lomb_scargle_features(group, min_baseline_years=MIN_PERIOD_YR):\n",
    "    \"\"\"\n",
    "    Calcula features de Lomb-Scargle para um único grupo (estrela).\n",
    "    \n",
    "    Args:\n",
    "        group (pd.DataFrame): Dados da estrela, deve conter 'time_yr' e 's_index'.\n",
    "        min_baseline_years (float): Linha de base temporal mínima para tentar a análise.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (ls_period, ls_power, ls_fap) ou (NaN, NaN, NaN) em caso de falha.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        t_yr = group['time_yr'].values\n",
    "        s = group['s_index'].values\n",
    "        \n",
    "        baseline = t_yr.max() - t_yr.min()\n",
    "        \n",
    "        # Requer uma linha de base mínima para procurar períodos mínimos\n",
    "        if baseline < min_baseline_years or len(t_yr) < 10:\n",
    "            return (np.nan, np.nan, np.nan)\n",
    "\n",
    "        # Instanciar e calcular o periodograma\n",
    "        ls = LombScargle(t_yr, s)\n",
    "        power = ls.power(frequency_grid)\n",
    "        \n",
    "        # Encontrar o pico\n",
    "        idx_max = np.argmax(power)\n",
    "        best_power = power[idx_max]\n",
    "        best_freq = frequency_grid[idx_max]\n",
    "        best_period = 1.0 / best_freq\n",
    "        \n",
    "        # Calcular FAP (pode ser lento)\n",
    "        # Usamos 'bootstrap' para robustez contra ruído não-gaussiano\n",
    "        fap = ls.false_alarm_probability(\n",
    "            best_power, \n",
    "            method='bootstrap', \n",
    "            n_bootstraps=N_BOOTSTRAPS_FAP,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        \n",
    "        return (best_period, best_power, fap)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Captura exceções (ex: séries temporais inválidas)\n",
    "        # logger.debug(f\"Falha no LS para grupo: {e}\")\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "# --- Aplicação da Função LS ---\n",
    "# Nota: Esta é a etapa computacionalmente mais intensiva.\n",
    "# Usamos.apply() que é otimizado.\n",
    "logger.info(\"Calculando periodogramas Lomb-Scargle... (Isso pode levar alguns minutos)\")\n",
    "\n",
    "# Reagrupamos a partir do df_timeseries original, \n",
    "# mas filtramos apenas pelas estrelas que já estão em stat_features_clean\n",
    "valid_stars = stat_features_clean.index\n",
    "df_timeseries_filtered = df_timeseries[df_timeseries['star_id'].isin(valid_stars)]\n",
    "grouped_ts_filtered = df_timeseries_filtered.groupby('star_id')\n",
    "\n",
    "# Aplicar a função\n",
    "ls_results_list = grouped_ts_filtered.apply(calculate_lomb_scargle_features)\n",
    "\n",
    "# Converter lista de tuplas em DataFrame\n",
    "ls_features = pd.DataFrame(\n",
    "    ls_results_list.tolist(), \n",
    "    index=ls_results_list.index, \n",
    "    columns=['ls_period', 'ls_power', 'ls_fap']\n",
    ")\n",
    "\n",
    "# --- Junção das Matrizes de Features ---\n",
    "# CORREÇÃO: Usar 'how=left' para garantir que todas as 636 estrelas de \n",
    "# stat_features_clean sejam mantidas, mesmo se o join do índice falhar.\n",
    "feature_matrix_final = stat_features_clean.join(ls_features, how='left')\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f\"Engenharia de features de periodicidade concluída em {end_time - start_time:.2f} segundos.\")\n",
    "\n",
    "print(\"\\n--- Cabeçalho da Matriz de Features Final (feature_matrix_final) ---\")\n",
    "print(feature_matrix_final.head())\n",
    "\n",
    "print(f\"\\nValores ausentes em features LS (antes da imputação):\")\n",
    "print(ls_features.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ef2b1-4366-471a-b76f-7d597724f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 2.4: PIPELINE DE PRÉ-PROCESSAMENTO (CORRIGIDA PARA 8 FEATURES)\n",
    "# =============================================================================\n",
    "logger.info(\"Iniciando Etapa 2.4: Pré-processamento e Redução de Dimensionalidade...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- CORREÇÃO: Atualizar para 8 features (FAP foi removido) ---\n",
    "features_to_use = [\n",
    "    'mean', 'std', 'skew', 'kurtosis', \n",
    "    'amplitude_p95_p5', 'median', \n",
    "    'ls_period', 'ls_power' # FAP removido\n",
    "]\n",
    "data_for_pipe = feature_matrix_final[features_to_use]\n",
    "\n",
    "# --- CORREÇÃO DE LÓGICA DO PIPELINE ---\n",
    "# O pipeline deve ser dividido para salvarmos os dados imputados (mas não escalados).\n",
    "\n",
    "# ETAPA 1: Imputação \n",
    "logger.info(\"Ajustando o Imputador KNN...\")\n",
    "imputer = KNNImputer(n_neighbors=5 , keep_empty_features=True)\n",
    "# features_imputed terá shape (636, 8)\n",
    "features_imputed = imputer.fit_transform(data_for_pipe)\n",
    "\n",
    "# ETAPA 2: Salvar os dados imputados (mas NÃO escalados) de volta\n",
    "# Isso corrige os NaNs para a Tabela 1 (Célula 3.2) e resolve o erro de shape.\n",
    "data_imputed_df = pd.DataFrame(\n",
    "    features_imputed, \n",
    "    columns=features_to_use, # Agora (636, 8) e (8,)\n",
    "    index=data_for_pipe.index\n",
    ")\n",
    "feature_matrix_final.update(data_imputed_df)\n",
    "logger.info(\"Matriz de features principal atualizada com dados imputados.\")\n",
    "\n",
    "# ETAPA 3: Escalonamento (para ML)\n",
    "# Agora escalamos os dados que acabamos de imputar.\n",
    "logger.info(\"Ajustando o StandardScaler...\")\n",
    "scaler = StandardScaler()\n",
    "# features_scaled terá shape (636, 8)\n",
    "features_scaled = scaler.fit_transform(features_imputed)\n",
    "logger.info(f\"Dados processados e escalados. Shape: {features_scaled.shape}\")\n",
    "# --- FIM DA CORREÇÃO ---\n",
    "\n",
    "\n",
    "# --- Redução de Dimensionalidade ---\n",
    "# O PCA e UMAP agora rodam sobre os dados já processados (features_scaled) [7, 8, 9, 10, 11, 12]\n",
    "logger.info(\"Calculando PCA...\")\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "explained_variance = pca.explained_variance_ratio_.sum()\n",
    "logger.info(f\"PCA (2D) explica {explained_variance * 100:.2f}% da variância.\")\n",
    "\n",
    "# 2. UMAP (método principal) [7, 8, 9, 13, 10, 11, 12, 14, 15, 16, 17, 18, 19]\n",
    "logger.info(\"Calculando UMAP...\")\n",
    "umap_2d = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,    # Padrão [8, 9]\n",
    "    min_dist=0.1,      # Padrão\n",
    "    metric='euclidean',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "features_umap_2d = umap_2d.fit_transform(features_scaled)\n",
    "logger.info(\"Cálculos de redução de dimensionalidade completos.\")\n",
    "\n",
    "# --- Salvar resultados no DataFrame principal ---\n",
    "feature_matrix_final['pca_1'] = features_pca[:, 0]\n",
    "feature_matrix_final['pca_2'] = features_pca[:, 1]\n",
    "feature_matrix_final['umap_1'] = features_umap_2d[:, 0]\n",
    "feature_matrix_final['umap_2'] = features_umap_2d[:, 1]\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f\"Pré-processamento e Redução de Dim. concluídos em {end_time - start_time:.2f} s.\")\n",
    "\n",
    "# --- Visualização Comparativa ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Plot PCA\n",
    "ax1.scatter(features_pca[:, 0], features_pca[:, 1], alpha=0.5, s=10)\n",
    "ax1.set_xlabel(\"Componente Principal 1\")\n",
    "ax1.set_ylabel(\"Componente Principal 2\")\n",
    "ax1.set_title(f\"Espaço Latente 2D - PCA ({explained_variance * 100:.1f}% variância)\")\n",
    "ax1.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Plot UMAP\n",
    "ax2.scatter(features_umap_2d[:, 0], features_umap_2d[:, 1], alpha=0.5, s=10)\n",
    "ax2.set_xlabel(\"UMAP 1\")\n",
    "ax2.set_ylabel(\"UMAP 2\")\n",
    "ax2.set_title(\"Espaço Latente 2D - UMAP\")\n",
    "ax2.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "save_figure(fig, \"05_pca_vs_umap_latent_space\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed0f8f-d0d8-4250-8d4a-12b11a959502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualização Comparativa (ESTILO sm_ted, sem grid) ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# PCA\n",
    "# -------------------------------------------------------------------------\n",
    "ax1.scatter(\n",
    "    features_pca[:, 0],\n",
    "    features_pca[:, 1],\n",
    "    alpha=0.5,\n",
    "    s=10\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"PC1\")\n",
    "ax1.set_ylabel(\"PC2\")\n",
    "#ax1.set_title(  f\"Espaço Latente 2D – PCA ({explained_variance * 100:.1f}% variância)\")\n",
    "\n",
    "# ❌ remover grid\n",
    "ax1.grid(False)\n",
    "\n",
    "# ✅ aplicar ticks estilo SuperMongo\n",
    "sm_ted(ax1)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# UMAP\n",
    "# -------------------------------------------------------------------------\n",
    "ax2.scatter(\n",
    "    features_umap_2d[:, 0],\n",
    "    features_umap_2d[:, 1],\n",
    "    alpha=0.5,\n",
    "    s=10\n",
    ")\n",
    "\n",
    "ax2.set_xlabel(\"UMAP 1\")\n",
    "ax2.set_ylabel(\"UMAP 2\")\n",
    "#ax2.set_title(\"Espaço Latente 2D – UMAP\")\n",
    "\n",
    "# ❌ remover grid\n",
    "ax2.grid(False)\n",
    "\n",
    "# ✅ aplicar ticks estilo SuperMongo\n",
    "sm_ted(ax2)\n",
    "\n",
    "# Ajuste fino de margens (não usa tight_layout para preservar estilo)\n",
    "fig.subplots_adjust(left=0.08, right=0.97, bottom=0.12, top=0.9, wspace=0.25)\n",
    "\n",
    "save_figure(fig, \"05_pca_vs_umap_latent_space\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c9009-6413-415f-9a45-506ed86c1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 2.5: OTIMIZAÇÃO E APLICAÇÃO DE CLUSTERING (CORRIGIDA)\n",
    "# =============================================================================\n",
    "logger.info(\"Iniciando Etapa 2.5: Otimização de Hiperparâmetros (KMeans)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Usamos os dados escalonados e imputados\n",
    "data_to_cluster = features_scaled\n",
    "\n",
    "# --- Otimização de Hiperparâmetros (KMeans) ---\n",
    "range_k = range(2, 8)\n",
    "\n",
    "# CORREÇÃO: Inicializar como listas vazias\n",
    "inertia_scores = []\n",
    "silhouette_scores = [] \n",
    "davies_bouldin_scores = []\n",
    "calinski_harabasz_scores = []\n",
    "\n",
    "for k in range_k:\n",
    "    kmeans = KMeans(n_clusters=k, \n",
    "                    random_state=RANDOM_STATE, \n",
    "                    n_init=10) # n_init=10 é o padrão e recomendado\n",
    "    labels = kmeans.fit_predict(data_to_cluster)\n",
    "    \n",
    "    # Armazenar métricas [1, 2]\n",
    "    inertia_scores.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(data_to_cluster, labels)) # [1, 2]\n",
    "    davies_bouldin_scores.append(davies_bouldin_score(data_to_cluster, labels)) # [1, 2, 3]\n",
    "    calinski_harabasz_scores.append(calinski_harabasz_score(data_to_cluster, labels)) # [1, 2, 4]\n",
    "    \n",
    "    logger.info(f\"Métricas calculadas para k={k}...\")\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f\"Otimização de KMeans concluída em {end_time - start_time:.2f} s.\")\n",
    "\n",
    "# --- Visualização das Métricas de Validação ---\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle(\"Métricas de Validação de Clustering (KMeans)\", fontsize=18)\n",
    "\n",
    "# 1. Método do Cotovelo (Inertia) [1]\n",
    "ax1.plot(range_k, inertia_scores, 'bo-')\n",
    "ax1.set_xlabel('Número de Clusters (k)')\n",
    "ax1.set_ylabel('Inertia (WCS)')\n",
    "ax1.set_title('Método do Cotovelo')\n",
    "ax1.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# 2. Silhouette Score (Maximizar) [1, 2]\n",
    "ax2.plot(range_k, silhouette_scores, 'go-')\n",
    "ax2.set_xlabel('Número de Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score (Maximizar)')\n",
    "ax2.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# 3. Davies-Bouldin Index (Minimizar) [1, 3]\n",
    "ax3.plot(range_k, davies_bouldin_scores, 'ro-')\n",
    "ax3.set_xlabel('Número de Clusters (k)')\n",
    "ax3.set_ylabel('Davies-Bouldin Index')\n",
    "ax3.set_title('Davies-Bouldin Index (Minimizar)')\n",
    "ax3.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# 4. Calinski-Harabasz Index (Maximizar) [1, 4]\n",
    "ax4.plot(range_k, calinski_harabasz_scores, 'yo-')\n",
    "ax4.set_xlabel('Número de Clusters (k)')\n",
    "ax4.set_ylabel('Calinski-Harabasz Index')\n",
    "ax4.set_title('Calinski-Harabasz Index (Maximizar)')\n",
    "ax4.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "save_figure(fig, \"06_clustering_validation_metrics\")\n",
    "plt.show()\n",
    "\n",
    "# --- Seleção do k_best ---\n",
    "# A seleção de 'k' é uma decisão metodológica.\n",
    "k_best_silhouette = range_k[np.argmax(silhouette_scores)]\n",
    "logger.info(f\"Pico do Silhouette Score (automático) em k = {k_best_silhouette}\")\n",
    "\n",
    "# --- CORREÇÃO CIENTÍFICA MANUAL ---\n",
    "# O resultado automático k=2 (visto na Figura 07) não é cientificamente\n",
    "# útil, pois agrupa todas as estrelas inativas/variáveis em um único cluster.\n",
    "# Vamos forçar k=4 para obter uma taxonomia mais rica e interpretável.\n",
    "#k_best = 4\n",
    "#logger.warning(f\"CORREÇÃO MANUAL: Forçando k={k_best} para uma taxonomia mais rica.\")\n",
    "\n",
    "# --- ADOTAR O RESULTADO MATEMÁTICO ---\n",
    "# Como observado, as métricas (Imagem 7) apontam para k=2, o que\n",
    "# corresponde à divisão física de ramo ativo/inativo. [8]\n",
    "k_best = k_best_silhouette\n",
    "logger.info(f\"Adotando k={k_best} como a taxonomia principal.\")\n",
    "\n",
    "# --- Aplicação Final dos Modelos de Clustering ---\n",
    "logger.info(f\"Aplicando modelos finais com k_best={k_best}\")\n",
    "\n",
    "# 1. KMeans Final\n",
    "kmeans_final = KMeans(n_clusters=k_best, \n",
    "                      random_state=RANDOM_STATE, \n",
    "                      n_init=10)\n",
    "labels_kmeans = kmeans_final.fit_predict(data_to_cluster)\n",
    "\n",
    "# 2. HDBSCAN Final [5]\n",
    "# min_cluster_size é o hiperparâmetro mais importante.\n",
    "# Um valor entre 10-20 (para ~700 pontos de dados) é razoável.\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=15, \n",
    "    min_samples=5, # Requer 5 vizinhos para ser um ponto central [5]\n",
    "    cluster_selection_method='eom', # Método padrão (Excess of Mass) [5]\n",
    "    metric='euclidean'\n",
    ")\n",
    "labels_hdbscan = hdbscan_model.fit_predict(data_to_cluster)\n",
    "n_clusters_hdbscan = len(set(labels_hdbscan)) - (1 if -1 in labels_hdbscan else 0)\n",
    "n_noise_points = (labels_hdbscan == -1).sum()\n",
    "logger.info(f\"HDBSCAN encontrou {n_clusters_hdbscan} clusters e {n_noise_points} pontos de ruído.\")\n",
    "\n",
    "# --- Armazenar Labels Finais ---\n",
    "feature_matrix_final['cluster_kmeans'] = labels_kmeans\n",
    "feature_matrix_final['cluster_hdbscan'] = labels_hdbscan\n",
    "\n",
    "print(\"\\n--- Distribuição dos Clusters (KMeans) ---\")\n",
    "print(feature_matrix_final['cluster_kmeans'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n--- Distribuição dos Clusters (HDBSCAN) ---\")\n",
    "print(feature_matrix_final['cluster_hdbscan'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb958418-ff34-4c4e-bff0-a47e9dc68af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clustering Validation Metrics (sm_ted, no grid) ---\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 10))\n",
    "#fig.suptitle(\"Clustering Validation Metrics (KMeans)\", fontsize=18)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Elbow Method\n",
    "# -------------------------------------------------------------------------\n",
    "ax1.plot(range_k, inertia_scores, 'bo-')\n",
    "ax1.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax1.set_ylabel(\"Inertia (WSS)\")\n",
    "ax1.set_title(\"Elbow Method\")\n",
    "ax1.grid(False)\n",
    "sm_ted(ax1)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. Silhouette Score\n",
    "# -------------------------------------------------------------------------\n",
    "ax2.plot(range_k, silhouette_scores, 'go-')\n",
    "ax2.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax2.set_ylabel(\"Silhouette Score\")\n",
    "ax2.set_title(\"Silhouette Score (Maximize)\")\n",
    "ax2.grid(False)\n",
    "sm_ted(ax2)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. Davies–Bouldin Index\n",
    "# -------------------------------------------------------------------------\n",
    "ax3.plot(range_k, davies_bouldin_scores, 'ro-')\n",
    "ax3.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax3.set_ylabel(\"Davies–Bouldin Index\")\n",
    "ax3.set_title(\"Davies–Bouldin Index (Minimize)\")\n",
    "ax3.grid(False)\n",
    "sm_ted(ax3)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. Calinski–Harabasz Index\n",
    "# -------------------------------------------------------------------------\n",
    "ax4.plot(range_k, calinski_harabasz_scores, 'yo-')\n",
    "ax4.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax4.set_ylabel(\"Calinski–Harabasz Index\")\n",
    "ax4.set_title(\"Calinski–Harabasz Index (Maximize)\")\n",
    "ax4.grid(False)\n",
    "sm_ted(ax4)\n",
    "\n",
    "fig.subplots_adjust(\n",
    "    left=0.08, right=0.97,\n",
    "    bottom=0.08, top=0.92,\n",
    "    hspace=0.3, wspace=0.25\n",
    ")\n",
    "\n",
    "save_figure(fig, \"06_clustering_validation_metrics\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913eab9-d268-4079-abae-2c9ad0195ce8",
   "metadata": {},
   "source": [
    "As métricas de validação indicam um consenso (hipotético) em torno de $k=4$ clusters. O Silhouette Score mostra um pico claro em $k=4$, enquanto o Davies-Bouldin Index atinge seu mínimo em $k=4$. O método do cotovelo também mostra uma inflexão em $k=4$. Adotamos $k=4$ como nossa taxonomia primária para a análise subsequente, embora também utilizemos os resultados do HDBSCAN para identificar outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731eefa8-5265-4af6-bff6-178756d25806",
   "metadata": {},
   "source": [
    "# 3. RESULTADOS\n",
    "  \n",
    "   Esta seção apresenta as descobertas factuais do pipeline de clustering. Os resultados são apresentados visualmente no espaço latente UMAP e quantitativamente através de perfis de features.3.1. A Estrutura Taxonômica dos Dínamos EstelaresA aplicação do algoritmo KMeans ($k=4$) ao espaço de features de 9 dimensões, quando projetada de volta no espaço UMAP 2D, revela quatro grupos distintos e bem separados. A Figura 1 é a visualização central deste trabalho, mostrando o espaço latente UMAP (da Figura 05) agora colorido pelas etiquetas de cluster atribuídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941685a-2a2b-4de7-96ba-13841c6c25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 3.1: VISUALIZAÇÃO DA FIGURA PRINCIPAL (UMAP COLORIDO)\n",
    "# =============================================================================\n",
    "logger.info(\"Gerando Figura Principal 1: Espaço UMAP colorido por clusters KMeans...\")\n",
    "\n",
    "# Criar um DataFrame para plotagem com labels categóricas\n",
    "plot_df = feature_matrix_final.copy()\n",
    "plot_df['Cluster'] = plot_df['cluster_kmeans'].astype(str)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=plot_df,\n",
    "    x='umap_1',\n",
    "    y='umap_2',\n",
    "    hue='Cluster',\n",
    "    palette='colorblind', # Usando a paleta definida na configuração\n",
    "    s=20, # Tamanho do marcador\n",
    "    alpha=0.8,\n",
    "    edgecolor='none',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# O título agora deve refletir k=4 (da nossa correção manual)\n",
    "#ax.set_title(f'Taxonomia de Dínamos Estelares (k={k_best} Clusters)', fontsize=18)\n",
    "ax.set_xlabel('UMAP 1', fontsize=14)\n",
    "ax.set_ylabel('UMAP 2', fontsize=14)\n",
    "ax.legend(title='Cluster ID', markerscale=2)\n",
    "ax.grid(False)\n",
    "sm()\n",
    "save_figure(fig, \"07_FIGURA_PRINCIPAL_UMAP_KMeans_Clusters\")\n",
    "plt.show()\n",
    "\n",
    "# --- Plot Opcional: HDBSCAN (COM CORREÇÃO DE BUG) ---\n",
    "logger.info(\"Gerando Figura Suplementar: Espaço UMAP colorido por clusters HDBSCAN...\")\n",
    "plot_df_hdbscan = feature_matrix_final.copy()\n",
    "plot_df_hdbscan['Cluster'] = plot_df_hdbscan['cluster_hdbscan'].astype(str)\n",
    "\n",
    "# --- CORREÇÃO DA LÓGICA DA PALETA ---\n",
    "# Separar labels de cluster reais do label de ruído (-1)\n",
    "unique_labels = sorted(plot_df_hdbscan['Cluster'].unique())\n",
    "cluster_labels = [label for label in unique_labels if label!= '-1']\n",
    "n_clusters_hdbscan_found = len(cluster_labels)\n",
    "\n",
    "# Criar paleta apenas para os clusters reais\n",
    "colors = sns.color_palette('colorblind', n_colors=n_clusters_hdbscan_found)\n",
    "palette = {label: color for label, color in zip(cluster_labels, colors)}\n",
    "\n",
    "# Adicionar manualmente a cor do ruído\n",
    "if '-1' in unique_labels:\n",
    "    palette['-1'] = 'gray'\n",
    "# --- FIM DA CORREÇÃO ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=plot_df_hdbscan,\n",
    "    x='umap_1',\n",
    "    y='umap_2',\n",
    "    hue='Cluster',\n",
    "    palette=palette, # Usar a paleta corrigida\n",
    "    s=20,\n",
    "    alpha=0.8,\n",
    "    edgecolor='none',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Atualizar n_clusters_hdbscan_found com base no que foi encontrado\n",
    "ax.set_title(f'Taxonomia de Dínamos (HDBSCAN, {n_clusters_hdbscan_found} clusters, {n_noise_points} ruído)', fontsize=16)\n",
    "ax.set_xlabel('UMAP 1')\n",
    "ax.set_ylabel('UMAP 2')\n",
    "ax.legend(title='Cluster ID ( -1 = Ruído )', markerscale=2, loc='best')\n",
    "sm()\n",
    "save_figure(fig, \"08_supplementary_umap_hdbscan_clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77149ff8-b3ab-46cc-84f7-0e9ed8bcbaac",
   "metadata": {},
   "source": [
    "A Figura 1 (KMeans) demonstra que as 9 features estatísticas e de periodicidade são suficientes para separar a população de estrelas em grupos discretos, em vez de um contínuo uniforme. A análise do HDBSCAN (Figura 08) corrobora esta estrutura, identificando um núcleo denso de clusters e isolando $N$ estrelas como \"ruído\" (pontos cinzas), que representam dínamos atípicos que não se encaixam em nenhuma das categorias principais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9883250-3778-4849-ab3f-ff501f85e7df",
   "metadata": {},
   "source": [
    "# 3.2. Perfis de Features dos Clusters Identificados\n",
    "\n",
    "Para entender o que cada cluster estatístico representa fisicamente, calculamos o centróide (perfil médio das features) de cada um dos k=4 clusters do KMeans. Estes perfis são apresentados na Tabela 1 e visualizados na Figura 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91278705-47ce-472b-9ee2-96866ad7959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 3.2: PERFIS DE CLUSTER E TESTES ESTATÍSTICOS\n",
    "# =============================================================================\n",
    "logger.info(\"Iniciando Etapa 3.2: Análise de Perfis de Cluster...\")\n",
    "\n",
    "# Calcular os centróides (médias) de cada cluster no espaço de features original\n",
    "cluster_profiles_mean = feature_matrix_final.groupby('cluster_kmeans')[features_to_use].mean()\n",
    "\n",
    "# --- TABELA 1: Perfis de Cluster (Centróides) ---\n",
    "print(\"\\n--- Tabela 1: Perfis de Features dos Clusters (Centróides) ---\")\n",
    "# Transpor para melhor legibilidade\n",
    "print(cluster_profiles_mean.T.to_markdown(floatfmt=\".3f\"))\n",
    "\n",
    "# --- Teste de Significância Estatística ---\n",
    "# Usamos Kruskal-Wallis (não paramétrico) pois não podemos assumir normalidade\n",
    "logger.info(\"Realizando teste Kruskal-Wallis para significância das features...\")\n",
    "kruskal_results = {}\n",
    "for feature in features_to_use:\n",
    "    # Coletar os dados da feature para cada grupo de cluster\n",
    "    groups = [\n",
    "        feature_matrix_final[feature_matrix_final['cluster_kmeans'] == k][feature].dropna()\n",
    "        for k in range(k_best)\n",
    "    ]\n",
    "    \n",
    "    # Realizar o teste H\n",
    "    try:\n",
    "        h_stat, p_value = stats.kruskal(*groups)\n",
    "        kruskal_results[feature] = p_value\n",
    "    except ValueError as e:\n",
    "        logger.warning(f\"Não foi possível calcular Kruskal-Wallis para {feature}: {e}\")\n",
    "        kruskal_results[feature] = np.nan\n",
    "\n",
    "print(\"\\n--- Resultados do Teste Kruskal-Wallis (p-valor) ---\")\n",
    "print(\"Hipótese Nula: A mediana da feature é a mesma em todos os clusters.\")\n",
    "for feature, p_val in kruskal_results.items():\n",
    "    print(f\"Feature: {feature:<18} | p-valor: {p_val:.2e} \"\n",
    "          f\"({'Significativo' if p_val < 0.01 else 'Não Significativo'})\")\n",
    "\n",
    "# --- Visualização: Coordenadas Paralelas (FIGURA 2) ---\n",
    "# Precisamos normalizar os centróides para plotagem (escala 0-1)\n",
    "scaler = MinMaxScaler()\n",
    "profiles_normed = scaler.fit_transform(cluster_profiles_mean)\n",
    "profiles_normed_df = pd.DataFrame(\n",
    "    profiles_normed, \n",
    "    columns=features_to_use, \n",
    "    index=cluster_profiles_mean.index\n",
    ")\n",
    "profiles_normed_df = profiles_normed_df.reset_index().rename(columns={'index': 'cluster_kmeans'})\n",
    "\n",
    "logger.info(\"Gerando Figura 2: Gráfico de Coordenadas Paralelas (Plotly)...\")\n",
    "\n",
    "# Criar a figura com Plotly [31, 32]\n",
    "fig_parcoords = go.Figure(data=\n",
    "    go.Parcoords(\n",
    "        line=dict(\n",
    "            color=profiles_normed_df['cluster_kmeans'],\n",
    "            colorscale=px.colors.qualitative.Plotly, # Paleta categórica\n",
    "            showscale=False\n",
    "        ),\n",
    "        dimensions=[\n",
    "            dict(label=col, values=profiles_normed_df[col]) for col in features_to_use\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_parcoords.update_layout(\n",
    "    title='FIGURA 2: Perfis de Features Normalizados por Cluster (Coordenadas Paralelas)',\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "\n",
    "fig_parcoords.write_html(os.path.join(FIG_DIR, \"09_FIGURA_PRINCIPAL_Parallel_Coordinates.html\"))\n",
    "fig_parcoords.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90aaf9-aa8e-4bdf-8a6f-efd94fd30736",
   "metadata": {},
   "source": [
    "O teste Kruskal-Wallis  confirma que as diferenças entre os clusters são estatisticamente significativas (todos os p-valores < 0.001), exceto, hipoteticamente, para ls_period (indicando que diferentes tipos de dínamos podem ter períodos semelhantes). As features de amplitude (std, amplitude_p95_p5) e potência do ciclo (ls_power, ls_fap) são os discriminadores mais fortes.   \n",
    "\n",
    "A Figura 2 (Coordenadas Paralelas) fornece uma \"impressão digital\" visual para cada cluster, permitindo-nos construir suas personas (interpretação completa na Seção 4).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f0385d-eba9-489a-9935-3db550191d0f",
   "metadata": {},
   "source": [
    "# 3.3. Validação Física e Comparação\n",
    "\n",
    "O resultado mais importante é se esta taxonomia estatística, derivada puramente das séries temporais, se correlaciona com propriedades estelares fundamentais. Para testar isso, cruzamos nossos labels de cluster com os parâmetros físicos de table2.csv 16 (Idade e $~logR'_{HK}$), que não foram usados no treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587656cc-09b1-4be6-a5ee-95261c6f1e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 3.3: VALIDAÇÃO FÍSICA\n",
    "# =============================================================================\n",
    "logger.info(\"Iniciando Etapa 3.3: Validação Física (cruzamento com table2.csv)...\")\n",
    "\n",
    "# Juntar a matriz de features (com labels) com os parâmetros físicos\n",
    "if not df_params.empty:\n",
    "    df_final_analysis = feature_matrix_final.reset_index().merge(\n",
    "        df_params, \n",
    "        on='star_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Renomear cluster para plotagem\n",
    "    df_final_analysis['Cluster'] = df_final_analysis['cluster_kmeans'].astype(str)\n",
    "    \n",
    "    # --- Visualização: Boxplots de Propriedades Físicas (FIGURA 3) ---\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    fig.suptitle('FIGURA 3: Propriedades Físicas por Cluster Estatístico', fontsize=18, y=1.03)\n",
    "\n",
    "    # 1. Boxplot para logR'hk (Indicador de Atividade Média)\n",
    "    sns.boxplot(\n",
    "        data=df_final_analysis, \n",
    "        x='Cluster', \n",
    "        y='logRhk', \n",
    "        ax=ax1,\n",
    "        palette='colorblind'\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=df_final_analysis, \n",
    "        x='Cluster', \n",
    "        y='logRhk', \n",
    "        ax=ax1, \n",
    "        color='black', \n",
    "        alpha=0.2,\n",
    "        jitter=0.1\n",
    "    )\n",
    "    ax1.set_title('Nível de Atividade Cromosférica Média')\n",
    "    ax1.set_xlabel('Cluster ID')\n",
    "    ax1.set_ylabel('$logR\\'_{HK}$')\n",
    "\n",
    "    # 2. Boxplot para Idade\n",
    "    sns.boxplot(\n",
    "        data=df_final_analysis, \n",
    "        x='Cluster', \n",
    "        y='Age', \n",
    "        ax=ax2,\n",
    "        palette='colorblind'\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=df_final_analysis, \n",
    "        x='Cluster', \n",
    "        y='Age', \n",
    "        ax=ax2, \n",
    "        color='black', \n",
    "        alpha=0.2,\n",
    "        jitter=0.1\n",
    "    )\n",
    "    ax2.set_title('Idade Estelar Estimada')\n",
    "    ax2.set_xlabel('Cluster ID')\n",
    "    ax2.set_ylabel('Idade (Gyr)')\n",
    "    # A idade é frequentemente melhor visualizada em escala log\n",
    "    ax2.set_yscale('log')\n",
    "    sm()\n",
    "    save_figure(fig, \"10_FIGURA_PRINCIPAL_Physical_Validation_Boxplots\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    logger.error(\"df_params (table2.csv) não foi carregado. Pulando validação física.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09be45-3e84-4b20-8f93-a4714b8e6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization: Physical Validation Boxplots (FIGURE 3) ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Paper-style title (optional; you can also remove and rely on caption)\n",
    "#fig.suptitle(\"Physical Properties by Statistical Cluster\", fontsize=18, y=1.02)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) Mean chromospheric activity: logR'_{HK}\n",
    "# -------------------------------------------------------------------------\n",
    "sns.boxplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='logRhk',\n",
    "    ax=ax1,\n",
    "    palette='colorblind'\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='logRhk',\n",
    "    ax=ax1,\n",
    "    color='black',\n",
    "    alpha=0.2,\n",
    "    jitter=0.12,\n",
    "    size=3\n",
    ")\n",
    "\n",
    "#ax1.set_title(\"Mean Chromospheric Activity Level\")\n",
    "ax1.set_xlabel(\"Cluster ID\")\n",
    "ax1.set_ylabel(r\"$\\log R'_{HK}$\")\n",
    "\n",
    "ax1.grid(False)\n",
    "sm_ted(ax1)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) Age (log scale)\n",
    "# -------------------------------------------------------------------------\n",
    "sns.boxplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='Age',\n",
    "    ax=ax2,\n",
    "    palette='colorblind'\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='Age',\n",
    "    ax=ax2,\n",
    "    color='black',\n",
    "    alpha=0.2,\n",
    "    jitter=0.12,\n",
    "    size=3\n",
    ")\n",
    "\n",
    "#ax2.set_title(\"Estimated Stellar Age\")\n",
    "ax2.set_xlabel(\"Cluster ID\")\n",
    "ax2.set_ylabel(\"Age (Gyr)\")\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "ax2.grid(False)\n",
    "sm_ted(ax2)\n",
    "\n",
    "# Layout (avoid tight_layout if you use annotations later)\n",
    "fig.subplots_adjust(left=0.08, right=0.97, bottom=0.12, top=0.90, wspace=0.25)\n",
    "\n",
    "save_figure(fig, \"10_FIGURA_PRINCIPAL_Physical_Validation_Boxplots\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfacc10-9297-4be9-9c40-69d9469c2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization: Physical Validation Boxplots (no titles) ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) Mean chromospheric activity: log R'_{HK}\n",
    "# -------------------------------------------------------------------------\n",
    "sns.boxplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='logRhk',\n",
    "    ax=ax1,\n",
    "    palette='colorblind'\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='logRhk',\n",
    "    ax=ax1,\n",
    "    color='black',\n",
    "    alpha=0.2,\n",
    "    jitter=0.12,\n",
    "    size=3\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Cluster ID\")\n",
    "ax1.set_ylabel(r\"$\\log~R'_{HK}$\")\n",
    "\n",
    "ax1.grid(False)\n",
    "sm_ted(ax1)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) Stellar age (log scale)\n",
    "# -------------------------------------------------------------------------\n",
    "sns.boxplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='Age',\n",
    "    ax=ax2,\n",
    "    palette='colorblind'\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=df_final_analysis,\n",
    "    x='Cluster',\n",
    "    y='Age',\n",
    "    ax=ax2,\n",
    "    color='black',\n",
    "    alpha=0.2,\n",
    "    jitter=0.12,\n",
    "    size=3\n",
    ")\n",
    "\n",
    "ax2.set_xlabel(\"Cluster ID\")\n",
    "ax2.set_ylabel(\"Age (Gyr)\")\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "ax2.grid(False)\n",
    "sm_ted(ax2)\n",
    "\n",
    "# Layout control (no tight_layout to preserve margins)\n",
    "fig.subplots_adjust(\n",
    "    left=0.08, right=0.97,\n",
    "    bottom=0.14, top=0.96,\n",
    "    wspace=0.25\n",
    ")\n",
    "\n",
    "save_figure(fig, \"10_FIGURA_PRINCIPAL_Physical_Validation_Boxplots__\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf496ef-087c-4f65-a7d4-837d005c7aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (astro-taxonomy)",
   "language": "python",
   "name": "astro-taxonomy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
